Сделано в Whisper AI
Твой RAG Это Шерлок С Гибридным Поиском (Hybrid Search) https://youtu.be/fanTV8CmdqQ
Чистая версия. Дата создания: ⁨13.01.2026⁩
Друзья, всем привет! Ну что, как отметили праздники? Готовы учиться новому? Вы когда-нибудь замечали, что ваш рак-агент вообще не очень находит данные? Ну то есть вы спрашиваете что-нибудь конкретное, а чанкс информации, которая вам нужна, либо в выборке попадает на одно из последних мест, либо вообще не попадает. Ну, например, вы что-нибудь спросили, расскажи мне про ограничение ответственности в документе из пункта 12.3. И если в этом документе встречается масса мест, где сказано про ограничение ответственности, то пункт 12.3 может вообще остаться незамеченным, либо иметь низкий приоритет. Это происходит потому, что векторный поиск работает на основе поископодобия. И в данном запросе ему скорее важна фраза ограничения ответственности, а не конкретный пункт. И резонный вопрос, а возможно ли построить такого Шерлока Холмса, который и точные запросы будет понимать буквально до одного слова, и общие вопросы, смысловые, тоже будет понимать. Ну, конечно, можно все это построить. И все это решается с помощью, как вы уже, наверное, знаете, гибридного поиска. И сегодня, к концу этого видео, мы с вами построим агента, который работает на основе гибридного поиска и ищет ваши данные с невероятной точностью. Но у меня для вас три базовых условия. Сначала лайк, потом подписка там внизу и обязательно какой-то коммент, чтобы нашу с вами беседу увидела как можно больше людей. Погнали строить! инструкция. Тут, естественно, я предполагаю, что у вас уже установлен супабейс. Если не установлено, то мы это делали тысячи раз. Посмотрите вот в этом видео, там полная подробная инструкция. Разверните себе супабейс и возвращайтесь сюда. И вся эта история строится на таком понятии, как reciprocal ranked fusion или объединение обратных рангов. Мы не будем с вами глубоко в это копать, но в общем и целом система будет искать рейтинги подобия для вашего запроса как по ключевым словам, так и по семантическому поиску. И итоговый ранг будет строиться на основе объединения результатов двух этих поисков, что повышает точность вашего поиска и уносит куда-то к небесам. И самое сладкое, что нам понадобится буквально несколько телодвижений. Создать табличку, создать индексы к ней, ну и саму функцию поиска. Мы это обычно и делаем, когда создаем таблицы для векторного поиска, помните? Давайте не расусоливать, сразу идем в SuperBase. Открываю свою локальную SuperBase, здесь ищу SQL Editor. Возвращаюсь в документацию SuperBase и нам говорят создайте новую таблицу документы. Забираю этот SQL-код, вставляю. Давайте создадим таблицу с названием документы 6, просто потому что у меня же много подобных таблиц. И здесь обратите внимание, размер вектора 512. Если вы используете эмбеддинги от OpenAI, то здесь нужно указать 1536, ну и выполнить запрос. Делаем. Получаем ошибку, что тип Extensions Vector не существует. Мы просто здесь убираем слово Extensions, оставляем только Vector. Нажимаем еще раз Run. Все. Наша таблица создана. Сразу идем в Table Editor. Проверяем. Видим, что вот она наша таблица, где есть сразу четыре важных поля. ID, сам контент. Теперь тут есть поле FTS с типом TS Vector и наши привычные мэддинги. Кажется, что пока все идет по плану. Но сразу, чтобы два раза не вставать, давайте я нажму «Редактировать таблицу», потому что мы с вами забыли добавить мета-данные, а мы чаще всего же используем мета-данные. Здесь добавляем столбец, его называем «MetaData», и тип у него обязательно JSON-B. Нажимаем «Save», проверяем, что вот наш столбец появился. Отлично, нам это и нужно было. Здесь возвращаемся обратно в SQL Editor, потом в документацию. И видим, что теперь нам нужно создать два индекса к этой таблице. Забираем SQL, вставляем сюда. Таблица у нас называется Document6. Здесь прокидываем, прокидываем, нажимаем Run. Все, success. Как мы это проверяем? Идем здесь в датабейс, потом ищем индексы, и видим вот наши индексы для таблицы Document6. Прекрасно, идем обратно в документацию. Теперь нам говорят создайте функцию гибридного поиска. Давайте заберем эту функцию, вернемся к нам в SuperBase, опять откроем SQL Editor, вставим все. И давайте ее внимательно-внимательно отсмотрим. Во-первых, я назову ее гибридный поиск 6, чтобы потом не запутаться. Размерность вектора 1536. Убираем слово Extensions, оно нам не понадобится. И везде, где я встречаю слово Documents, я меняю на Documents 6. И здесь, и здесь, и здесь. Нажимаем Выполнить. Отлично, и у нас создалась функция гибридного поиска, которая называется Hybrid Search 6. Возвращаемся в документацию Superbase, и дальше нам рассказано, каким образом ее можно использовать. Сказано, если хотите, просто выполняйте SQL-запрос, ну а лучше создайте себе Edge-функцию, то есть это функция, написанная на JavaScript или TypeScript. И по сути, что она будет делать, она будет наш запрос превращать сначала в эмбеддинг, потом реализовывать функцию поиска и семантического, и по ключевым словам, и будет нам возвращать результаты. Но это, если честно, чуть геморно, я предлагаю вариант покруче. Сразу идем в NVC Man. Так, вот мой n8n, я нажимаю здесь Create Workflow, сразу добавлю чат, потому что я буду через чат общаться с моим гибридным поиском. И давайте еще раз посмотрим на гибридный поиск в документации Superbase. Я прямо вижу, что здесь есть две ключевые штуки. Сначала мы можем передавать непосредственной строку поиска, по которой будет осуществляться поиск по ключевым словам. А дальше я вижу, что мы можем передать вектор, То есть это вектор нашего запроса, и вот эту вот комбинированную историю мы передаем в нашу функцию гибридного поиска, и SupaBase делает все за нас. Ну, вернее, сама функция. А можем ли мы вручную все это сделать? Да, конечно, можем. Мы почти все можем. Идем в NVC Main, и я хочу прямо запрос пользователя. Вот я тут ввожу слово «Привет». Я хочу прямо этот «Привет» сначала викторизовать, а потом уже подставлять в наш SQL запрос, который будет уходить в SupaBase. Как будто бы звучит логично. Каким образом мы что-то можем викторизовать вручную? Мы знаем, что почти у каждого провайдера нейронок есть свои нейронки для эмбеддингов, для викторизации. Давайте попробуем прямо поискать OpenAI. Здесь внутри посмотрим, что есть. Есть покоммуницировать с моделью, есть анализ картинок, есть генерация аудио, файлы. Но если честно, что-то не вижу, что тут есть прямо прямой вызов модели для эмбеддингов, но это нас не должно останавливать. Потому что всегда есть универсальная нода, которая нас спасала с вами тысячу раз. Называется http-запрос. Добавляю эту ноду. И мы сейчас будем слать запросы на викторизацию вообще вручную. Это будет пост-запрос, конечно. Куда мы шлем? Я вот только что посмотрел, что нужно слать api.openai.com.embeddings. Аутентификация нам нужна, поэтому воспользуемся такой магической штукой, как предопределенные карденшалы. Выбираем этот тип. Если вы уже где-то в других нодах использовали креды от любых сервисов, то Вы всегда можете к ним постучаться через эту функциональность. Вот я нашел здесь OpenAI, и он говорит, здесь уже в твоем n8n содержатся такие креды, хочешь, буду использовать. Да, я хочу, потому что по сути он эти креды будет подставлять в хедр запроса, и мне не нужно прописывать здесь ничего вручную. Ну вот я хочу послать единственное Body, здесь выбираю JSON, и опять же, я только что посмотрел в документации, запрос на викторизацию шлется очень просто. Мы указываем модель, нам нужна текст Embedding Tree Small, мы постоянно ей пользуемся, а дальше сам текст, сама строка, которую мы будем викторизовать. А ведь она у нас есть здесь, в Chat Input, я просто взял, перекинул сюда Chat Input, и по сути нас ничего не останавливает перед тем, чтобы викторизовать наше слово «Привет». Давайте выполним этот шаг. О, вау, о, вау, нам OpenAI вернул эмбеддинги для нашего слова «привет», то есть это вектор для нашей фразы. Сейчас чувствуете, да, как магия вообще раскрывается? То, что обычно для нас n8man скрывает под своим капотом внутри нод, мы сейчас прямо делаем вручную. По сути, это же самое происходит, когда вы просто добавляете ноду superbass-vector-store и закидываете в нее чанки, вот происходит то же самое. Каждый чанк проходит через процесс векторизации, и мы получаем наши векторы. Теперь вернемся в документацию SuperBase, и нам сказано, вот так общайтесь с нашим гибридным поиском, поэтому забираем этот сниппет, возвращаемся в n8n. И каким образом мы можем слать SQL-запросы в нашу SuperBase? Ну, по факту, в Postgres, который лежит в основе SuperBase. Так и ищем ноду Postgres, добавляем ее, и здесь есть функция «Выполнить SQL-запрос», нажимаем ее, здесь есть поле для SQL-запроса, вставляем его, но сейчас на него посмотрим повнимательнее. Кредо я поменяю на свои локальные. Так, сама функция называется в нашем случае HybridSearch6, мы ее сами так назвали. Дальше сам запрос. Зачем нам итальянский соус? Нам он не нужен, но запрос-то у нас лежит изначально в нашем chat.input, поэтому я прям беру его сюда, закидываю. И дальше он говорит, закинь мне векторы. А векторы ведь мы только что с вами сгенерировали, поэтому убираем вот эти скобочки. Мы видим, что наши векторы в поле Embedding лежат. Прямо закидываем сюда их. Смотрим внизу, каким образом это все он рендерит. Смотрите, наш вектор тут лежит в поле массив. Нас это точно не устраивает, потому что Postgres отплюнется, потому что ему нужен только вектор. Никакое слово массив ему не нужно. Поэтому используем бронебойный довод королей. Мы здесь пишем json.stringify и забираем в скобочки всю нашу переменную. Смотрим теперь, как рендерится наш вектор Отлично, теперь формат Top Ну что, давайте выполнять Смотрим, как это будет работать Так, ошибка та же самая Убираем слово Extensions Ну и конечно же размерность 1536 Мы с вами забыли поменять Теперь опять выполняем Нету никаких данных Но это потому, что у нас в самой таблице ничего нету Давайте туда что-нибудь загоним Ищем ноду Superbase VectorStore Нажимаем тут «Добавить документы в VectorStore» Указываем здесь правильную табличку, да, мы с вами только что создали документ 6 А вот в опциях мы должны указать функцию поиска И она у нас называется HybridSearch6 Эта функция используется не только для получения данных из векторного хранилища, но еще и для правильной записи Потому что там происходит много магии внутри. Дальше модель для эмбендингов та же самая, только теперь через официальную ноду. Ну и самый большой вопрос, откуда мы документы берем? Вы берите оттуда, где они у вас лежат, а я заберу из своего Obsidian. Мы недавно с вами учились забирать файлы из Obsidian и викторизовать их с помощью n8n. Вот они у меня всей кучкой лежат. Поэтому я воспользуюсь своей старой функцией, которая держит в актуальности мой Obsidian и викторизует все заметки. Кстати, топовая тема, посмотрите вот в этом видео. Как только мы что-то будем добавлять в Obsidian, все эти знания будут викторизоваться и будут доступны нашему агенту, как нашему второму мозгу. Но это сейчас не тема разговора. Я просто нажимаю выполнение workflow, он сам все делает за меня. Поэтому мы с вами просто возвращаемся в Superbase и смотрим, что у нас в нашей таблице с документами. Обратите внимание, начало очень похожее. Здесь есть просто контент моих заметок. А дальше в поле FTS есть вот такие прекрасные значения. Они выглядят мега странно, но в этом есть и вся соль поиска по ключевым словам. Этот процесс называется стемминг. То есть, по сути, система упрощает наш текст, разбивает его по словам и проставляет специальные ранги. на основе того, насколько важно это слово в тексте. Там прикольный процесс. Система смотрит, сколько раз слово встречается в тексте, где его позиция ближе к началу или ближе к концу, какая плотность его в этом тексте, ну и насколько он, в принципе, редкий. Дальше в таблице идут привычные нам эмбеддинги, векторы, ну и метаданные, которые мы заблаговременно добавили как столбец в нашу таблицу. Кстати, друзья, если вы переживаете за эту автоматизацию, каким образом тут происходит все, то в конце каждого видео я нажимаю кнопочку Download и скачиваю JSON этой автоматизации и сохраняю в свою бесплатную Telegram-группу. Вы идете, открываете эту группу, находите релевантное вам видео, которое вам нравится, под этим видео ищите файл, джейсон файл, нажимаете скачать его, загружаете через тот же самый принцип обратно себе в n8n и продолжаете экспериментировать. А все усложненные автоматизации закидываю себе в Pro группу, ссылка на нее тоже будет в описании, там вообще куча всего про n8n, автоматизацию, искусственный интеллект, туда тоже обязательно заскакивайте, проверяйте внизу. Ну что, давайте уже тестировать. Я напишу что-нибудь очень простое, чтобы как раз мы могли проверить эффективность поиска по ключевым словам. Я напишу только одно слово, пускай это будет слово «учеба». Нажимаю Enter. Вижу, как сейчас викторизуется мое слово, и потом наш SQL-запрос возвращает нам релевантные чанки. И смотрите, прямо по одному запросу в самом верху, на самом первом месте стоит чанк про учебу с персональным e-тьютором. И вы можете увидеть, как отрабатывает Full Text Search, каким образом расставлены ранги каждого слова. И вообще говоря, это релевантная запись, которую я держал у себя в голове, которую мы нашли прямо с первого раза батному слову. Давайте сейчас попробуем отдельно провести векторный поиск по этому же самому слову, не используя поиск по словам. Вот мой старый агент, который смотрит на мою ту же самую таблицу, но использует функцию не гибридного поиска, а векторного. Итак, я пишу слово «учеба», отправляю сюда, смотрим, как работает агент, вызывает наш VectorStore. И смотрите, какой чанг у нас самый релевантный по мнению векторного поиска. Мгновенный перевод речи в ухи — это конец изучения языков как необходимости. И это есть то самое базовое отличие, про которое мы говорили в самом начале. Когда я сказал слово «учеба», то векторный поиск пытается организовать поиск по смыслу. И так как он нашел чанг про изучение, то есть по смысловой нагрузке это реально про учебу. сам чанк был нерелевантен для конкретно моего кейса. Именно поэтому следует внедрять гибридный поиск, который будет объединять результаты поиска векторного и поиска по ключевым словам в единую конструкцию и отдавать уже агенту вашему объединенные результаты. Ну что, друзья, мы на этом будем заканчивать. Вот эту автоматизацию, которую мы с вами только что построили, забирайте в бесплатной Telegram-группе. Если вам интересна автоматизация, которая прямо из вашего Obsidian забирает файлы, векторизует их и помещает в вашу векторную базу для гибридного поиска, то забирайте ее в нашей Pro группе. Ссылка на оба ресурса у нас в описании. А на этом все.